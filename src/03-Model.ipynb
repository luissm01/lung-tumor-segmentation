{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moral-scenario",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we define the model used for lung tumor segmentation.\n",
    "\n",
    "The architecture remains unchanged from the atrium segmentation task. We will use the U-Net, one of the most widely adopted architectures for medical image segmentation, originally proposed in [Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597).\n",
    "\n",
    "Its encoder-decoder structure with skip connections makes it particularly effective for detecting both large and small structures, which is essential for identifying tumors in CT scans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alone-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-python",
   "metadata": {},
   "source": [
    "## U-Net Architecture for Medical Image Segmentation\n",
    "\n",
    "U-Net is a convolutional neural network architecture widely used for biomedical image segmentation. It was originally proposed in 2015 for segmenting cells in microscopy images, but has since become a standard baseline for many medical imaging tasks.\n",
    "\n",
    "Our implementation is a custom 2D U-Net designed to segment lung tumors slice by slice.\n",
    "\n",
    "---\n",
    "\n",
    "### Structure of the U-Net\n",
    "\n",
    "U-Net follows an **encoder-decoder** structure with skip connections. The idea is to **capture context** using a contracting path (encoder), and then **enable precise localization** using an expanding path (decoder) with high-resolution features from earlier layers.\n",
    "\n",
    "#### 1. **Encoder (Downsampling Path)**\n",
    "\n",
    "The encoder progressively reduces spatial dimensions while increasing the number of feature channels. It consists of:\n",
    "\n",
    "- **DoubleConv blocks**: two `Conv2D + BatchNorm + ReLU` layers\n",
    "- **MaxPooling layers**: halve the spatial resolution after each block\n",
    "\n",
    "This part allows the model to extract increasingly abstract features from the image.\n",
    "\n",
    "#### 2. **Bottleneck**\n",
    "\n",
    "After the last downsampling step, a `Dropout` is applied to prevent overfitting. This is useful because this layer has a large receptive field and contains the most compressed representation of the input.\n",
    "\n",
    "#### 3. **Decoder (Upsampling Path)**\n",
    "\n",
    "The decoder gradually restores the spatial resolution of the feature maps:\n",
    "\n",
    "- **Upsample + 1x1 conv**: used to double the spatial size and reduce the number of channels\n",
    "- **Concatenation with skip connections**: merges low-level features from the encoder\n",
    "- **DoubleConv**: refines the merged features\n",
    "\n",
    "This part allows the network to combine context and detailed information to produce accurate segmentation masks.\n",
    "\n",
    "#### 4. **Final Prediction Layer**\n",
    "\n",
    "- A final block of `Conv + ReLU + Conv` is applied.\n",
    "- The output is a single-channel **logit map** (no sigmoid), suitable for use with loss functions like `BCEWithLogitsLoss`.\n",
    "\n",
    "---\n",
    "\n",
    "### How the Data Flows Through the Model\n",
    "\n",
    "Let’s assume the input is a single CT slice of shape `[1, 256, 256]`.\n",
    "\n",
    "1. **Input** → `down1` → feature map `[64, 256, 256]`\n",
    "2. ↓ `MaxPool`  \n",
    "3. → `down2` → `[128, 128, 128]`\n",
    "4. ↓ `MaxPool`  \n",
    "5. → `down3` → `[256, 64, 64]`\n",
    "6. ↓ `MaxPool`  \n",
    "7. → `down4` → `[512, 32, 32]`  \n",
    "8. → `Dropout`  \n",
    "9. ↑ `Upsample` + `1x1 conv`  \n",
    "10. → concat with `down3` → `up_conv1` → `[256, 64, 64]`  \n",
    "11. ↑ and repeat...  \n",
    "12. Final output → `[1, 256, 256]`\n",
    "\n",
    "---\n",
    "\n",
    "### Key Enhancements\n",
    "\n",
    "- **Batch Normalization**: stabilizes learning and helps with convergence.\n",
    "- **Dropout**: used at the bottleneck to reduce overfitting.\n",
    "- **Xavier Initialization**: sets good initial weights for all convolutions.\n",
    "- **No Sigmoid**: we output raw logits, which is more numerically stable when used with appropriate loss functions.\n",
    "\n",
    "---\n",
    "\n",
    "### Output\n",
    "\n",
    "The model returns a 2D tensor of shape `[1, H, W]`, where each pixel contains the predicted probability (logit) of being part of the tumor. During inference, you can apply a sigmoid followed by thresholding to convert it into a binary mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "macro-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies two consecutive Conv2D + BatchNorm + ReLU blocks.\n",
    "    Used for both downsampling and upsampling stages.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net encoder-decoder architecture for binary segmentation tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder (downsampling path)\n",
    "        self.down1 = DoubleConv(1, 64)\n",
    "        self.down2 = DoubleConv(64, 128)\n",
    "        self.down3 = DoubleConv(128, 256)\n",
    "        self.down4 = DoubleConv(256, 512)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Decoder (upsampling path)\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(512, 256, kernel_size=1)  # Channel reduction before concat\n",
    "        )\n",
    "        self.up_conv1 = DoubleConv(512, 256)  # 256 from upsample + 256 from skip connection\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=1)\n",
    "        )\n",
    "        self.up_conv2 = DoubleConv(256, 128)\n",
    "\n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=1)\n",
    "        )\n",
    "        self.up_conv3 = DoubleConv(128, 64)\n",
    "\n",
    "        # Final prediction head (no activation for logits)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size=1)  # Output logits\n",
    "        )\n",
    "\n",
    "        # Dropout at bottleneck to prevent overfitting\n",
    "        self.dropout = nn.Dropout2d(0.2)\n",
    "\n",
    "        # Xavier initialization for better convergence\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(self.maxpool(x1))\n",
    "        x3 = self.down3(self.maxpool(x2))\n",
    "        x4 = self.down4(self.maxpool(x3))\n",
    "        x4 = self.dropout(x4)\n",
    "\n",
    "        # Decoder path with skip connections\n",
    "        xu1 = self.up1(x4)\n",
    "        xu1 = torch.cat([xu1, x3], dim=1)\n",
    "        xu1 = self.up_conv1(xu1)\n",
    "\n",
    "        xu2 = self.up2(xu1)\n",
    "        xu2 = torch.cat([xu2, x2], dim=1)\n",
    "        xu2 = self.up_conv2(xu2)\n",
    "\n",
    "        xu3 = self.up3(xu2)\n",
    "        xu3 = torch.cat([xu3, x1], dim=1)\n",
    "        xu3 = self.up_conv3(xu3)\n",
    "\n",
    "        return self.final(xu3)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize convolutional layers using Xavier normal initialization.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_normal_(m.weight, gain=1.0)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
